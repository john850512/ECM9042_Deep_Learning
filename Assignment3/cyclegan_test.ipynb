{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:26:44.962004Z",
     "start_time": "2019-06-09T16:26:44.520540Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load cyclegan_test.py\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import itertools\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from models import Generator\n",
    "from models import Discriminator\n",
    "from utils import ReplayBuffer\n",
    "from utils import weights_init_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:26:50.826757Z",
     "start_time": "2019-06-09T16:26:48.189011Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# parameters\n",
    "#TODO : set up all the parameters\n",
    "epochs =  150   # number of epochs of training\n",
    "batchsize = 200    # size of the batches\n",
    "animation_root = './animation'    # root directory of the dataset\n",
    "cartoon_root = './cartoon'    # root directory of the dataset\n",
    "lr = 2e-3    # initial learning rate\n",
    "size = 32    # size of the data crop (squared assumed)\n",
    "input_nc = 3     # number of channels of input data\n",
    "output_nc = 3    # number of channels of output data\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "###### Definition of variables ######\n",
    "# TODO : assign input_nc and output_nc\n",
    "\n",
    "# Networks\n",
    "netG_A2B = Generator(input_nc, output_nc)\n",
    "netG_B2A = Generator(output_nc, input_nc)\n",
    "\n",
    "# Load state dicts\n",
    "netG_A2B.load_state_dict(torch.load('ckpt/netG_A2B.pth'))\n",
    "netG_B2A.load_state_dict(torch.load('ckpt/netG_B2A.pth'))\n",
    "\n",
    "netG_A2B.to(device)\n",
    "netG_B2A.to(device)\n",
    "\n",
    "# Set model's test mode\n",
    "netG_A2B.eval()\n",
    "netG_B2A.eval()\n",
    "\n",
    "\n",
    "# Inputs & targets memory allocation\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
    "input_A = Tensor(batchsize, input_nc, size, size)\n",
    "input_B = Tensor(batchsize, output_nc, size, size)\n",
    "target_real = Variable(Tensor(batchsize).fill_(1.0), requires_grad=False)\n",
    "target_fake = Variable(Tensor(batchsize).fill_(0.0), requires_grad=False)\n",
    "\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "# Dataset loader\n",
    "transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "animation_set = torchvision.datasets.ImageFolder(animation_root, transform) \n",
    "cartoon_set = torchvision.datasets.ImageFolder(cartoon_root, transform) \n",
    "animation_loader = torch.utils.data.DataLoader(dataset=animation_set,batch_size=batchsize,shuffle=True)\n",
    "cartoon_loader = torch.utils.data.DataLoader(dataset=cartoon_set,batch_size=batchsize,shuffle=True)\n",
    "\n",
    "\n",
    "if not os.path.exists('output/animation'):\n",
    "    os.makedirs('output/animation')\n",
    "if not os.path.exists('output/cartoon'):\n",
    "    os.makedirs('output/cartoon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T16:27:32.805878Z",
     "start_time": "2019-06-09T16:27:17.467608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated images 0010\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i=0\n",
    "for batch in zip(animation_loader, cartoon_loader):\n",
    "    # Set model input\n",
    "    A = torch.FloatTensor(batch[0][0])\n",
    "    B = torch.FloatTensor(batch[1][0])\n",
    "    real_A = Variable(input_A.copy_(A))\n",
    "    real_B = Variable(input_B.copy_(B))\n",
    "\n",
    "    # Generate output\n",
    "    fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\n",
    "    fake_A = 0.5*(netG_B2A(real_B).data + 1.0)\n",
    "\n",
    "    # Save image files\n",
    "    save_image(real_A, 'output/animation/real%04d.png' % (i+1))\n",
    "    save_image(real_B, 'output/cartoon/real%04d.png' % (i+1))\n",
    "    save_image(fake_A, 'output/animation/fake%04d.png' % (i+1))\n",
    "    save_image(fake_B, 'output/cartoon/fake%04d.png' % (i+1))\n",
    "\n",
    "    sys.stdout.write('\\rGenerated images %04d' % (i+1))\n",
    "    i = i+1\n",
    "    if (i==10):\n",
    "        break\n",
    "\n",
    "sys.stdout.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
